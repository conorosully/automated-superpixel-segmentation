{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune models\n",
    "This script takes the models that have been pretrained on the superpixels approach and fine-tunes them on their respective datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from train import *\n",
    "import network\n",
    "\n",
    "base_path = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, target_pos, incl_bands, satellite):\n",
    "        self.target_pos = target_pos\n",
    "        self.incl_bands = incl_bands\n",
    "        self.satellite = satellite\n",
    "\n",
    "# Function to freeze layers except the final convolutional blocks\n",
    "def freeze_layers(model, unfrozen_layers):\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "        for layer in unfrozen_layers:\n",
    "            if layer in name:\n",
    "                param.requires_grad = True\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(model, name, loader, epochs=10, lr=0.001, model_path='../../models/'):\n",
    "    \"\"\"\n",
    "    Function to finetune a model on a new dataset\n",
    "        model: pretrained model\n",
    "        name: name of the model\n",
    "        loader: dataloader for the new dataset\n",
    "        epochs: number of epochs to train\n",
    "        lr: learning rate\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    device = torch.device('mps')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, target in iter(loader):\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Calculate validation loss\n",
    "        model = model.eval()\n",
    "\n",
    "        valid_loss = 0\n",
    "        for images, target in iter(loader):\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "        valid_loss /= len(loader)\n",
    "        print(f\"Epoch {epoch}: {round(valid_loss, 5)}\")\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), f'{model_path}{name}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos=-1\n",
    "incl_bands=[0, 1, 2, 3, 4, 5, 6,7,8,9,10,11]\n",
    "satellite=\"sentinel\"\n",
    "\n",
    "swed_finetune_file = base_path + 'SWED/finetune/'\n",
    "swed_finetune_paths = glob.glob(swed_finetune_file + '*.npy')\n",
    "print(len(swed_finetune_paths))\n",
    "    \n",
    "args = Args(target_pos, incl_bands, satellite)\n",
    "\n",
    "finetune_data = TrainDataset(swed_finetune_paths, args)\n",
    "finetune_loader = DataLoader(finetune_data, batch_size=10, shuffle=False)\n",
    "\n",
    "# Sense check the data\n",
    "for i, (X, y) in enumerate(finetune_loader):\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rough model\n",
    "device = torch.device('mps')  #UPDATE\n",
    "print(\"Using device: {}\\n\".format(device))\n",
    "swed_superpixel = \"SWED_SUPERPIXELS_26JUL2024.pth\"\n",
    "\n",
    "model = network.U_Net(12,2).to(device)\n",
    "\n",
    "# Load saved model \n",
    "#model = torch.load('../models/LANDSAT-UNET-20JUL23.pth', map_location=torch.device('cpu') )\n",
    "state_dict = torch.load(f'../../models/{swed_superpixel}', map_location=torch.device('cpu') )\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the final convolutional blocks\n",
    "unfrozen_layers = ['Up5','Up_conv5','Up4','Up_conv4','Up3','Up_conv3','Up2','Up_conv2', 'Conv_1x1']\n",
    "freeze_layers(model, unfrozen_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model(model, 'SWED-FINETUNE-30JUL24', finetune_loader, epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pos=-1\n",
    "incl_bands=[0, 1, 2, 3, 4, 5, 6]\n",
    "satellite=\"landsat\"\n",
    "\n",
    "lics_finetune_file = base_path + 'LICS/finetune/'\n",
    "lics_finetune_paths = glob.glob(lics_finetune_file + '*.npy')\n",
    "    \n",
    "args = Args(target_pos, incl_bands, satellite)\n",
    "\n",
    "finetune_data = TrainDataset(lics_finetune_paths, args)\n",
    "finetune_loader = DataLoader(finetune_data, batch_size=10, shuffle=False)\n",
    "\n",
    "\n",
    "# Sense check the data\n",
    "for i, (X, y) in enumerate(finetune_loader):\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load rough model\n",
    "device = torch.device('mps')  #UPDATE\n",
    "print(\"Using device: {}\\n\".format(device))\n",
    "lics_superpixel = \"LICS_SUPERPIXELS_26JUL2024.pth\"\n",
    "\n",
    "model = network.U_Net(7,2).to(device)\n",
    "\n",
    "# Load saved model \n",
    "#model = torch.load('../models/LANDSAT-UNET-20JUL23.pth', map_location=torch.device('cpu') )\n",
    "state_dict = torch.load(f'../../models/{lics_superpixel}', map_location=torch.device('cpu') )\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the final convolutional blocks\n",
    "unfrozen_layers = ['Up5','Up_conv5','Up4','Up_conv4','Up3','Up_conv3','Up2','Up_conv2', 'Conv_1x1']\n",
    "freeze_layers(model, unfrozen_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_model(model, 'LICS_FINETUNE_26JUL24', finetune_loader, epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lics_finetune_file = base_path + 'LICS/finetune/'\n",
    "lics_augment_file = base_path + 'LICS/finetune_augmentation/'\n",
    "lics_finetune_paths = glob.glob(lics_finetune_file + '*.npy')\n",
    "\n",
    "for path in lics_finetune_paths:\n",
    "    file = np.load(path)\n",
    "    name = os.path.basename(path)\n",
    "\n",
    "    # Save file to new directory\n",
    "    np.save(lics_augment_file + name, file)\n",
    "\n",
    "    # image shape is [7, 256, 256]\n",
    "    # rotate 90 degrees\n",
    "    file = np.rot90(file, axes=(0,1))\n",
    "    np.save(lics_augment_file + 'rot90_' + name, file)\n",
    "\n",
    "    # rotate 180 degrees\n",
    "    file = np.rot90(file, axes=(0,1))\n",
    "    np.save(lics_augment_file + 'rot180_' + name, file)\n",
    "\n",
    "    # rotate 270 degrees\n",
    "    file = np.rot90(file, axes=(0,1))\n",
    "    np.save(lics_augment_file + 'rot270_' + name, file)\n",
    "\n",
    "    # flip horizontally\n",
    "    file = np.fliplr(file)\n",
    "    np.save(lics_augment_file + 'fliph_' + name, file)\n",
    "\n",
    "    # flip vertically\n",
    "    file = np.flipud(file)\n",
    "    np.save(lics_augment_file + 'fliv_' + name, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
