{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune models\n",
    "This script takes the models that have been pretrained on the superpixels approach and fine-tunes them on their respective datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/conorosullivan/Documents/git/COASTAL MONITORING/superpixel-annotation/venv_sp/lib/python3.9/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from train import *\n",
    "import network\n",
    "\n",
    "base_path = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, target_pos, incl_bands, satellite):\n",
    "        self.target_pos = target_pos\n",
    "        self.incl_bands = incl_bands\n",
    "        self.satellite = satellite\n",
    "\n",
    "# Function to freeze layers except the final convolutional blocks\n",
    "def freeze_layers(model, unfrozen_layers):\n",
    "    for name, param in model.named_parameters():\n",
    "        param.requires_grad = False\n",
    "        for layer in unfrozen_layers:\n",
    "            if layer in name:\n",
    "                param.requires_grad = True\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(model, name, loader, epochs=10, lr=0.001, model_path='../../models/'):\n",
    "    \"\"\"\n",
    "    Function to finetune a model on a new dataset\n",
    "        model: pretrained model\n",
    "        name: name of the model\n",
    "        loader: dataloader for the new dataset\n",
    "        epochs: number of epochs to train\n",
    "        lr: learning rate\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    device = torch.device('mps')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, target in iter(loader):\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Calculate validation loss\n",
    "        model = model.eval()\n",
    "\n",
    "        valid_loss = 0\n",
    "        for images, target in iter(loader):\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "        valid_loss /= len(loader)\n",
    "        print(f\"Epoch {epoch}: {round(valid_loss, 5)}\")\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), f'{model_path}{name}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "torch.Size([10, 12, 256, 256])\n",
      "torch.Size([10, 2, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "target_pos=-1\n",
    "incl_bands=[0, 1, 2, 3, 4, 5, 6,7,8,9,10,11]\n",
    "satellite=\"sentinel\"\n",
    "\n",
    "swed_finetune_file = base_path + 'SWED/finetune/'\n",
    "swed_finetune_paths = glob.glob(swed_finetune_file + '*.npy')\n",
    "print(len(swed_finetune_paths))\n",
    "    \n",
    "args = Args(target_pos, incl_bands, satellite)\n",
    "\n",
    "finetune_data = TrainDataset(swed_finetune_paths, args)\n",
    "finetune_loader = DataLoader(finetune_data, batch_size=10, shuffle=False)\n",
    "\n",
    "# Sense check the data\n",
    "for i, (X, y) in enumerate(finetune_loader):\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "U_Net(\n",
       "  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv1): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(12, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up5): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up4): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up3): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up2): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv_1x1): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load rough model\n",
    "device = torch.device('mps')  #UPDATE\n",
    "print(\"Using device: {}\\n\".format(device))\n",
    "swed_superpixel = \"SWED_SUPERPIXELS_26JUL2024.pth\"\n",
    "\n",
    "model = network.U_Net(12,2).to(device)\n",
    "\n",
    "# Load saved model \n",
    "#model = torch.load('../models/LANDSAT-UNET-20JUL23.pth', map_location=torch.device('cpu') )\n",
    "state_dict = torch.load(f'../../models/{swed_superpixel}', map_location=torch.device('cpu') )\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the final convolutional blocks\n",
    "unfrozen_layers = ['Up5','Up_conv5','Up4','Up_conv4','Up3','Up_conv3','Up2','Up_conv2', 'Conv_1x1']\n",
    "freeze_layers(model, unfrozen_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.18848\n",
      "Epoch 1: 0.15869\n",
      "Epoch 2: 0.13616\n",
      "Epoch 3: 0.1251\n",
      "Epoch 4: 0.11853\n",
      "Epoch 5: 0.11535\n",
      "Epoch 6: 0.11391\n",
      "Epoch 7: 0.11138\n",
      "Epoch 8: 0.10938\n",
      "Epoch 9: 0.1081\n"
     ]
    }
   ],
   "source": [
    "finetune_model(model, 'SWED-FINETUNE-30JUL24', finetune_loader, epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 7, 256, 256])\n",
      "torch.Size([10, 2, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "target_pos=-1\n",
    "incl_bands=[0, 1, 2, 3, 4, 5, 6]\n",
    "satellite=\"landsat\"\n",
    "\n",
    "lics_finetune_file = base_path + 'LICS/finetune/'\n",
    "lics_finetune_paths = glob.glob(lics_finetune_file + '*.npy')\n",
    "    \n",
    "args = Args(target_pos, incl_bands, satellite)\n",
    "\n",
    "finetune_data = TrainDataset(lics_finetune_paths, args)\n",
    "finetune_loader = DataLoader(finetune_data, batch_size=10, shuffle=False)\n",
    "\n",
    "\n",
    "# Sense check the data\n",
    "for i, (X, y) in enumerate(finetune_loader):\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "U_Net(\n",
       "  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv1): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(7, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up5): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up4): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up3): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up2): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up_conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv_1x1): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load rough model\n",
    "device = torch.device('mps')  #UPDATE\n",
    "print(\"Using device: {}\\n\".format(device))\n",
    "lics_superpixel = \"LICS_SUPERPIXELS_26JUL2024.pth\"\n",
    "\n",
    "model = network.U_Net(7,2).to(device)\n",
    "\n",
    "# Load saved model \n",
    "#model = torch.load('../models/LANDSAT-UNET-20JUL23.pth', map_location=torch.device('cpu') )\n",
    "state_dict = torch.load(f'../../models/{lics_superpixel}', map_location=torch.device('cpu') )\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the final convolutional blocks\n",
    "unfrozen_layers = ['Up5','Up_conv5','Up4','Up_conv4','Up3','Up_conv3','Up2','Up_conv2', 'Conv_1x1']\n",
    "freeze_layers(model, unfrozen_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 0.06655\n",
      "Epoch 1: 0.05389\n",
      "Epoch 2: 0.04447\n",
      "Epoch 3: 0.03856\n",
      "Epoch 4: 0.0347\n",
      "Epoch 5: 0.03203\n",
      "Epoch 6: 0.03009\n",
      "Epoch 7: 0.02853\n",
      "Epoch 8: 0.02721\n",
      "Epoch 9: 0.02604\n"
     ]
    }
   ],
   "source": [
    "finetune_model(model, 'LICS_FINETUNE_26JUL24', finetune_loader, epochs=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lics_finetune_file = base_path + 'LICS/finetune/'\n",
    "lics_augment_file = base_path + 'LICS/finetune_augmentation/'\n",
    "lics_finetune_paths = glob.glob(lics_finetune_file + '*.npy')\n",
    "\n",
    "for path in lics_finetune_paths:\n",
    "    file = np.load(path)\n",
    "    name = os.path.basename(path)\n",
    "\n",
    "    # Save file to new directory\n",
    "    np.save(lics_augment_file + name, file)\n",
    "\n",
    "    # image shape is [7, 256, 256]\n",
    "    # rotate 90 degrees\n",
    "    file = np.rot90(file, axes=(0,1))\n",
    "    np.save(lics_augment_file + 'rot90_' + name, file)\n",
    "\n",
    "    # rotate 180 degrees\n",
    "    file = np.rot90(file, axes=(0,1))\n",
    "    np.save(lics_augment_file + 'rot180_' + name, file)\n",
    "\n",
    "    # rotate 270 degrees\n",
    "    file = np.rot90(file, axes=(0,1))\n",
    "    np.save(lics_augment_file + 'rot270_' + name, file)\n",
    "\n",
    "    # flip horizontally\n",
    "    file = np.fliplr(file)\n",
    "    np.save(lics_augment_file + 'fliph_' + name, file)\n",
    "\n",
    "    # flip vertically\n",
    "    file = np.flipud(file)\n",
    "    np.save(lics_augment_file + 'fliv_' + name, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
