{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LICS Evaluation \n",
    "Evaluate different segmentation approaches on the LICS test dataset. These include the deterministic superpixel algorithm, pretrained and finetuned U-Net model. The accuracy, precision, recall, F1 and FOM metrics are calculated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import train\n",
    "import network\n",
    "import torch\n",
    "\n",
    "import glob\n",
    "\n",
    "import importlib\n",
    "import evaluation as eval\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "importlib.reload(eval)\n",
    "\n",
    "base_path = '../../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model names\n",
    "lics_original = \"LICS_UNET_12JUL2024.pth\" #Previous SOTA approach (model from original LICS paper)\n",
    "# Note reuslts will be slightly differnet than LICS paper due to random seed\n",
    "lics_superpixel = \"LICS_SUPERPIXELS_26JUL2024.pth\" #Pretrained model trained on superpixel output\n",
    "lics_finetune = \"LICS_FINETUNE_26JUL24.pth\" #Fine-tuned model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LICS data\n",
    "incl_bands = [0,1,2,3,4,5,6]\n",
    "satellite = 'landsat'\n",
    "\n",
    "# Test data\n",
    "target_pos = -2\n",
    "\n",
    "lics_test_file = base_path + 'LICS/test/'\n",
    "lics_test_paths = glob.glob(lics_test_file + '*.npy')\n",
    "lics_test_targets = [np.load(file)[:,:,target_pos] for file in lics_test_paths]\n",
    "lics_test_input = [np.load(file)[:,:,incl_bands] for file in lics_test_paths]\n",
    "\n",
    "print(\"Test dimensions:\")\n",
    "print(np.shape(lics_test_targets))\n",
    "print(np.shape(lics_test_input))\n",
    "\n",
    "# Finetune data\n",
    "target_pos = -1\n",
    "\n",
    "lics_finetune_file = base_path + 'LICS/finetune/'\n",
    "lics_finetune_paths = glob.glob(lics_finetune_file + '*.npy')\n",
    "lics_finetune_targets = [np.load(file)[:,:,target_pos] for file in lics_finetune_paths]\n",
    "lics_finetune_input = [np.load(file)[:,:,incl_bands] for file in lics_finetune_paths]\n",
    "\n",
    "print(\"\\nFinetune dimensions:\")\n",
    "print(np.shape(lics_finetune_targets))\n",
    "print(np.shape(lics_finetune_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sense check the data\n",
    "\n",
    "# Test data\n",
    "i = np.random.randint(0,len(lics_test_paths))\n",
    "rgb = utils.get_rgb(lics_test_input[i],satellite=satellite,contrast=0.2)\n",
    "target = lics_test_targets[i]\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].imshow(rgb)\n",
    "ax[1].imshow(target)\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "\n",
    "# Finetune data\n",
    "i = np.random.randint(0,len(lics_finetune_paths))\n",
    "rgb = utils.get_rgb(lics_finetune_input[i],satellite=satellite,contrast=0.2)\n",
    "target = lics_finetune_targets[i]\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].imshow(rgb)\n",
    "ax[1].imshow(target, cmap='gray')\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Superpixel algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ititialize metrics\n",
    "lics_test_metrics = {}\n",
    "lics_finetune_metrics = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp_predictions(paths,satellite,rgb_bands,index_name,threshold = -1,method='slic', **kwargs):\n",
    "    # Copy the input image to avoid modifying the original\n",
    "    preds = []\n",
    "    for path in paths:\n",
    "        all_bands = np.load(path)\n",
    "        mask = utils.get_mask_from_bands(all_bands, \n",
    "                                         satellite=satellite,\n",
    "                                         rgb_bands=rgb_bands,\n",
    "                                         threshold=threshold, \n",
    "                                         index_name=index_name,\n",
    "                                         method=method, **kwargs)\n",
    "        preds.append(mask)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "preds_sp = get_sp_predictions(lics_test_paths,\n",
    "                           satellite='landsat',\n",
    "                           rgb_bands=[\"nir\", \"green\", \"blue\"],\n",
    "                           index_name=\"NDWI\",\n",
    "                           threshold=-1, \n",
    "                           method='felzenszwalb',\n",
    "                           min_size=60)\n",
    "\n",
    "metrics, arr = eval.eval_metrics(lics_test_targets,preds_sp)\n",
    "lics_test_metrics['superpixels'] = metrics\n",
    "eval.display_metrics(metrics,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune\n",
    "preds = get_sp_predictions(lics_finetune_paths,\n",
    "                            satellite='landsat',\n",
    "                            rgb_bands=[\"nir\", \"green\", \"blue\"],\n",
    "                            index_name=\"NDWI\",\n",
    "                            threshold=-1, \n",
    "                            method='felzenszwalb',\n",
    "                            min_size=60)\n",
    "\n",
    "metrics, arr = eval.eval_metrics(lics_finetune_targets,preds)\n",
    "lics_finetune_metrics['superpixels'] = metrics\n",
    "eval.display_metrics(metrics,arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('mps')  #UPDATE\n",
    "print(\"Using device: {}\\n\".format(device))\n",
    "\n",
    "model = network.U_Net(7,2).to(device)\n",
    "\n",
    "# Load saved model \n",
    "#model = torch.load('../models/LANDSAT-UNET-20JUL23.pth', map_location=torch.device('cpu') )\n",
    "state_dict = torch.load(f'../../models/{lics_original}', map_location=torch.device('cpu') )\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "targets, preds = eval.get_preds(model,lics_test_paths,target_pos=-2,incl_bands=incl_bands,satellite=satellite,batch_size=10)\n",
    "print(len(preds))\n",
    "\n",
    "metrics, arr = eval.eval_metrics(lics_test_targets ,preds)\n",
    "lics_test_metrics['original'] = metrics\n",
    "eval.display_metrics(metrics,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune\n",
    "targets, preds = eval.get_preds(model,lics_finetune_paths,target_pos=-1,incl_bands=incl_bands,satellite=satellite,batch_size=10)\n",
    "print(len(preds))\n",
    "\n",
    "metrics, arr = eval.eval_metrics(lics_finetune_targets ,preds)\n",
    "lics_finetune_metrics['original'] = metrics\n",
    "eval.display_metrics(metrics,arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('mps')  #UPDATE\n",
    "print(\"Using device: {}\\n\".format(device))\n",
    "\n",
    "model = network.U_Net(7,2).to(device)\n",
    "\n",
    "# Load saved model \n",
    "#model = torch.load('../models/LANDSAT-UNET-20JUL23.pth', map_location=torch.device('cpu') )\n",
    "state_dict = torch.load(f'../../models/{lics_superpixel}', map_location=torch.device('cpu') )\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "targets, preds_pretrained = eval.get_preds(model,lics_test_paths,target_pos=-2,incl_bands=incl_bands,satellite=satellite,batch_size=10)\n",
    "print(len(preds))\n",
    "\n",
    "metrics, arr = eval.eval_metrics(lics_test_targets ,preds_pretrained)\n",
    "lics_test_metrics['rough_model'] = metrics\n",
    "eval.display_metrics(metrics,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune\n",
    "targets, preds = eval.get_preds(model,lics_finetune_paths,target_pos=-1,incl_bands=incl_bands,satellite=satellite,batch_size=10)\n",
    "print(len(preds))\n",
    "\n",
    "metrics, arr = eval.eval_metrics(lics_finetune_targets ,preds)\n",
    "lics_finetune_metrics['rough_model'] = metrics\n",
    "eval.display_metrics(metrics,arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some predictions\n",
    "i = np.random.randint(0,len(lics_test_paths))\n",
    "rgb = utils.get_rgb(lics_test_input[i],satellite=satellite,contrast=0.2)\n",
    "target = lics_test_targets[i]\n",
    "pred = preds[i]\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "ax[0].imshow(rgb)\n",
    "ax[1].imshow(target)\n",
    "ax[2].imshow(pred)\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('mps')  #UPDATE\n",
    "print(\"Using device: {}\\n\".format(device))\n",
    "\n",
    "model = network.U_Net(7,2).to(device)\n",
    "\n",
    "# Load saved model \n",
    "#model = torch.load('../models/LANDSAT-UNET-20JUL23.pth', map_location=torch.device('cpu') )\n",
    "state_dict = torch.load(f'../../models/{lics_finetune}', map_location=torch.device('cpu') )\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "targets, preds_finetuned = eval.get_preds(model,lics_test_paths,target_pos=-2,incl_bands=incl_bands,satellite=satellite,batch_size=10)\n",
    "print(len(preds))\n",
    "\n",
    "metrics, arr = eval.eval_metrics(lics_test_targets ,preds_finetuned)\n",
    "lics_test_metrics['finetune_model'] = metrics\n",
    "eval.display_metrics(metrics,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some predictions\n",
    "i = np.random.randint(0,len(lics_test_paths))\n",
    "rgb = utils.get_rgb(lics_test_input[i],satellite=satellite,contrast=0.2)\n",
    "target = lics_test_targets[i]\n",
    "pred = preds[i]\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "ax[0].imshow(rgb)\n",
    "ax[1].imshow(target)\n",
    "ax[2].imshow(pred)\n",
    "\n",
    "for a in ax:\n",
    "    a.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune\n",
    "targets, preds = eval.get_preds(model,lics_finetune_paths,target_pos=-1,incl_bands=incl_bands,satellite=satellite,batch_size=10)\n",
    "print(len(preds))\n",
    "\n",
    "metrics, arr = eval.eval_metrics(lics_finetune_targets ,preds)\n",
    "lics_finetune_metrics['finetune_model'] = metrics\n",
    "eval.display_metrics(metrics,arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save metrics\n",
    "with open('lics_test_metrics.json', 'w') as f:\n",
    "    json.dump(lics_test_metrics, f)\n",
    "\n",
    "with open('lics_finetune_metrics.json', 'w') as f:\n",
    "    json.dump(lics_finetune_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test metrics\n",
    "df_test_metrics = pd.read_csv('lics_test_metrics.csv')\n",
    "df_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_metrics = json.load(open('lics_test_metrics.json'))\n",
    "df_test_metrics = pd.DataFrame(df_test_metrics)\n",
    "\n",
    "df_test_metrics = df_test_metrics[['original','superpixels','rough_model','finetune_model']]\n",
    "df_test_metrics = df_test_metrics.transpose()\n",
    "df_test_metrics = df_test_metrics[['accuracy','precision','recall','f1','fom']]\n",
    "np.round(df_test_metrics,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune metrics\n",
    "df_finetune_metrics = json.load(open('lics_finetune_metrics.json'))\n",
    "df_finetune_metrics = pd.DataFrame(df_finetune_metrics)\n",
    "\n",
    "df_finetune_metrics = df_finetune_metrics[['original','superpixels','rough_model','finetune_model']]\n",
    "df_finetune_metrics = df_finetune_metrics.transpose()\n",
    "df_finetune_metrics = df_finetune_metrics[['accuracy','precision','recall','f1','fom']]\n",
    "\n",
    "np.round(df_finetune_metrics,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = df_finetune_metrics[['accuracy']]\n",
    "accuracy['Test'] = df_test_metrics[['accuracy']]\n",
    "accuracy.columns = ['Finetune','Test']\n",
    "round(accuracy,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some predictions\n",
    "i = 84\n",
    "print(i)\n",
    "rgb = utils.get_rgb(lics_test_input[i],satellite=satellite,contrast=0.2)\n",
    "target = lics_test_targets[i]\n",
    "\n",
    "fig, ax = plt.subplots(1,5,figsize=(15,5))\n",
    "ax[0].imshow(rgb)\n",
    "ax[1].imshow(target, cmap='gray')\n",
    "ax[1].set_title(\"Ground Truth\")\n",
    "\n",
    "ax[2].imshow(preds_sp[i], cmap='gray')\n",
    "accuracy = np.sum(preds_sp[i] == target) / np.size(target)\n",
    "ax[2].set_title(\"Deterministic ({:.3f})\".format(accuracy))\n",
    "\n",
    "ax[3].imshow(preds_pretrained[i], cmap='gray')\n",
    "accuracy = np.sum(preds_pretrained[i] == target) / np.size(target)\n",
    "ax[3].set_title(\"Pretrained ({:.3f})\".format(accuracy))\n",
    "\n",
    "ax[4].imshow(preds_finetuned[i], cmap='gray')\n",
    "accuracy = np.sum(preds_finetuned[i] == target) / np.size(target)\n",
    "ax[4].set_title(\"Finetunned ({:.3f})\".format(accuracy))\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])\n",
    "\n",
    "#utils.save_fig(fig, 'inland_water_bodies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some predictions\n",
    "i = 16\n",
    "rgb = utils.get_rgb(lics_test_input[i],satellite=satellite,contrast=0.2)\n",
    "target = lics_test_targets[i]\n",
    "\n",
    "fig, ax = plt.subplots(1,5,figsize=(15,5))\n",
    "ax[0].imshow(rgb)\n",
    "ax[1].imshow(target, cmap='gray')\n",
    "ax[1].set_title(\"Ground Truth\")\n",
    "\n",
    "ax[2].imshow(preds_sp[i], cmap='gray')\n",
    "accuracy = np.sum(preds_sp[i] == target) / np.size(target)\n",
    "ax[2].set_title(\"Deterministic ({:.3f})\".format(accuracy))\n",
    "\n",
    "ax[3].imshow(preds_pretrained[i], cmap='gray')\n",
    "accuracy = np.sum(preds_pretrained[i] == target) / np.size(target)\n",
    "ax[3].set_title(\"Pretrained ({:.3f})\".format(accuracy))\n",
    "\n",
    "ax[4].imshow(preds_finetuned[i], cmap='gray')\n",
    "accuracy = np.sum(preds_finetuned[i] == target) / np.size(target)\n",
    "ax[4].set_title(\"Finetunned ({:.3f})\".format(accuracy))\n",
    "\n",
    "for a in ax:\n",
    "    a.set_xticks([])\n",
    "    a.set_yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
